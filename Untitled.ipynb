{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09acb107-b2ba-4fff-a9cb-ee3a2b5a132a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building dataset (this may take a while; you can limit tickers)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "['AAPL']: JSONDecodeError('Expecting value: line 1 column 1 (char 0)')\n",
      "\n",
      "1 Failed download:\n",
      "['AAPL']: JSONDecodeError('Expecting value: line 1 column 1 (char 0)')\n",
      "\n",
      "1 Failed download:\n",
      "['AAPL']: JSONDecodeError('Expecting value: line 1 column 1 (char 0)')\n",
      "\n",
      "1 Failed download:\n",
      "['AAPL']: JSONDecodeError('Expecting value: line 1 column 1 (char 0)')\n",
      "\n",
      "1 Failed download:\n",
      "['AAPL']: JSONDecodeError('Expecting value: line 1 column 1 (char 0)')\n",
      "\n",
      "1 Failed download:\n",
      "['AAPL']: JSONDecodeError('Expecting value: line 1 column 1 (char 0)')\n",
      "\n",
      "1 Failed download:\n",
      "['AAPL']: JSONDecodeError('Expecting value: line 1 column 1 (char 0)')\n",
      "\n",
      "1 Failed download:\n",
      "['AAPL']: JSONDecodeError('Expecting value: line 1 column 1 (char 0)')\n",
      "\n",
      "1 Failed download:\n",
      "['AAPL']: JSONDecodeError('Expecting value: line 1 column 1 (char 0)')\n",
      "\n",
      "1 Failed download:\n",
      "['AAPL']: JSONDecodeError('Expecting value: line 1 column 1 (char 0)')\n",
      "\n",
      "1 Failed download:\n",
      "['AAPL']: JSONDecodeError('Expecting value: line 1 column 1 (char 0)')\n",
      "Failed to get ticker 'MSFT' reason: Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "1 Failed download:\n",
      "['MSFT']: YFTzMissingError('$%ticker%: possibly delisted; no timezone found')\n",
      "Failed to get ticker 'MSFT' reason: Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "1 Failed download:\n",
      "['MSFT']: YFTzMissingError('$%ticker%: possibly delisted; no timezone found')\n",
      "Failed to get ticker 'MSFT' reason: Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "1 Failed download:\n",
      "['MSFT']: YFTzMissingError('$%ticker%: possibly delisted; no timezone found')\n",
      "Failed to get ticker 'MSFT' reason: Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "1 Failed download:\n",
      "['MSFT']: YFTzMissingError('$%ticker%: possibly delisted; no timezone found')\n",
      "Failed to get ticker 'MSFT' reason: Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "1 Failed download:\n",
      "['MSFT']: YFTzMissingError('$%ticker%: possibly delisted; no timezone found')\n",
      "Failed to get ticker 'MSFT' reason: Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "1 Failed download:\n",
      "['MSFT']: YFTzMissingError('$%ticker%: possibly delisted; no timezone found')\n",
      "Failed to get ticker 'MSFT' reason: Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "1 Failed download:\n",
      "['MSFT']: YFTzMissingError('$%ticker%: possibly delisted; no timezone found')\n",
      "Failed to get ticker 'MSFT' reason: Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "1 Failed download:\n",
      "['MSFT']: YFTzMissingError('$%ticker%: possibly delisted; no timezone found')\n",
      "Failed to get ticker 'MSFT' reason: Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "1 Failed download:\n",
      "['MSFT']: YFTzMissingError('$%ticker%: possibly delisted; no timezone found')\n",
      "Failed to get ticker 'MSFT' reason: Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "1 Failed download:\n",
      "['MSFT']: YFTzMissingError('$%ticker%: possibly delisted; no timezone found')\n",
      "Failed to get ticker 'MSFT' reason: Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "1 Failed download:\n",
      "['MSFT']: YFTzMissingError('$%ticker%: possibly delisted; no timezone found')\n",
      "Failed to get ticker 'AMZN' reason: Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "1 Failed download:\n",
      "['AMZN']: YFTzMissingError('$%ticker%: possibly delisted; no timezone found')\n",
      "Failed to get ticker 'AMZN' reason: Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "1 Failed download:\n",
      "['AMZN']: YFTzMissingError('$%ticker%: possibly delisted; no timezone found')\n",
      "Failed to get ticker 'AMZN' reason: Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "1 Failed download:\n",
      "['AMZN']: YFTzMissingError('$%ticker%: possibly delisted; no timezone found')\n",
      "Failed to get ticker 'AMZN' reason: Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "1 Failed download:\n",
      "['AMZN']: YFTzMissingError('$%ticker%: possibly delisted; no timezone found')\n",
      "Failed to get ticker 'AMZN' reason: Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "1 Failed download:\n",
      "['AMZN']: YFTzMissingError('$%ticker%: possibly delisted; no timezone found')\n",
      "Failed to get ticker 'AMZN' reason: Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "1 Failed download:\n",
      "['AMZN']: YFTzMissingError('$%ticker%: possibly delisted; no timezone found')\n",
      "Failed to get ticker 'AMZN' reason: Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "1 Failed download:\n",
      "['AMZN']: YFTzMissingError('$%ticker%: possibly delisted; no timezone found')\n",
      "Failed to get ticker 'AMZN' reason: Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "1 Failed download:\n",
      "['AMZN']: YFTzMissingError('$%ticker%: possibly delisted; no timezone found')\n",
      "Failed to get ticker 'AMZN' reason: Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "1 Failed download:\n",
      "['AMZN']: YFTzMissingError('$%ticker%: possibly delisted; no timezone found')\n",
      "Failed to get ticker 'AMZN' reason: Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "1 Failed download:\n",
      "['AMZN']: YFTzMissingError('$%ticker%: possibly delisted; no timezone found')\n",
      "Failed to get ticker 'AMZN' reason: Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "1 Failed download:\n",
      "['AMZN']: YFTzMissingError('$%ticker%: possibly delisted; no timezone found')\n",
      "Failed to get ticker 'GOOGL' reason: Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "1 Failed download:\n",
      "['GOOGL']: YFTzMissingError('$%ticker%: possibly delisted; no timezone found')\n",
      "Failed to get ticker 'GOOGL' reason: Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "1 Failed download:\n",
      "['GOOGL']: YFTzMissingError('$%ticker%: possibly delisted; no timezone found')\n",
      "Failed to get ticker 'GOOGL' reason: Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "1 Failed download:\n",
      "['GOOGL']: YFTzMissingError('$%ticker%: possibly delisted; no timezone found')\n",
      "Failed to get ticker 'GOOGL' reason: Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "1 Failed download:\n",
      "['GOOGL']: YFTzMissingError('$%ticker%: possibly delisted; no timezone found')\n",
      "Failed to get ticker 'GOOGL' reason: Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "1 Failed download:\n",
      "['GOOGL']: YFTzMissingError('$%ticker%: possibly delisted; no timezone found')\n",
      "Failed to get ticker 'GOOGL' reason: Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "1 Failed download:\n",
      "['GOOGL']: YFTzMissingError('$%ticker%: possibly delisted; no timezone found')\n",
      "Failed to get ticker 'GOOGL' reason: Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "1 Failed download:\n",
      "['GOOGL']: YFTzMissingError('$%ticker%: possibly delisted; no timezone found')\n",
      "Failed to get ticker 'GOOGL' reason: Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "1 Failed download:\n",
      "['GOOGL']: YFTzMissingError('$%ticker%: possibly delisted; no timezone found')\n",
      "Failed to get ticker 'GOOGL' reason: Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "1 Failed download:\n",
      "['GOOGL']: YFTzMissingError('$%ticker%: possibly delisted; no timezone found')\n",
      "Failed to get ticker 'GOOGL' reason: Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "1 Failed download:\n",
      "['GOOGL']: YFTzMissingError('$%ticker%: possibly delisted; no timezone found')\n",
      "Failed to get ticker 'GOOGL' reason: Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "1 Failed download:\n",
      "['GOOGL']: YFTzMissingError('$%ticker%: possibly delisted; no timezone found')\n",
      "Failed to get ticker 'TSLA' reason: Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "1 Failed download:\n",
      "['TSLA']: YFTzMissingError('$%ticker%: possibly delisted; no timezone found')\n",
      "Failed to get ticker 'TSLA' reason: Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "1 Failed download:\n",
      "['TSLA']: YFTzMissingError('$%ticker%: possibly delisted; no timezone found')\n",
      "Failed to get ticker 'TSLA' reason: Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "1 Failed download:\n",
      "['TSLA']: YFTzMissingError('$%ticker%: possibly delisted; no timezone found')\n",
      "Failed to get ticker 'TSLA' reason: Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "1 Failed download:\n",
      "['TSLA']: YFTzMissingError('$%ticker%: possibly delisted; no timezone found')\n",
      "Failed to get ticker 'TSLA' reason: Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "1 Failed download:\n",
      "['TSLA']: YFTzMissingError('$%ticker%: possibly delisted; no timezone found')\n",
      "Failed to get ticker 'TSLA' reason: Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "1 Failed download:\n",
      "['TSLA']: YFTzMissingError('$%ticker%: possibly delisted; no timezone found')\n",
      "Failed to get ticker 'TSLA' reason: Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "1 Failed download:\n",
      "['TSLA']: YFTzMissingError('$%ticker%: possibly delisted; no timezone found')\n",
      "Failed to get ticker 'TSLA' reason: Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "1 Failed download:\n",
      "['TSLA']: YFTzMissingError('$%ticker%: possibly delisted; no timezone found')\n",
      "Failed to get ticker 'TSLA' reason: Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "1 Failed download:\n",
      "['TSLA']: YFTzMissingError('$%ticker%: possibly delisted; no timezone found')\n",
      "Failed to get ticker 'TSLA' reason: Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "1 Failed download:\n",
      "['TSLA']: YFTzMissingError('$%ticker%: possibly delisted; no timezone found')\n",
      "Failed to get ticker 'TSLA' reason: Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "1 Failed download:\n",
      "['TSLA']: YFTzMissingError('$%ticker%: possibly delisted; no timezone found')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset rows: 0\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['momentum_1y', 'momentum_3y', 'vol_1y', 'avg_vol_1y', 'pe', 'pb',\\n       'div_yield', 'marketcap'],\\n      dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 207\u001b[39m\n\u001b[32m    204\u001b[39m df = build_dataset(sample_tickers=[\u001b[33m'\u001b[39m\u001b[33mAAPL\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mMSFT\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mAMZN\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mGOOGL\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mTSLA\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m    205\u001b[39m                    start_year=\u001b[32m2008\u001b[39m, end_year=\u001b[32m2018\u001b[39m)\n\u001b[32m    206\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mDataset rows:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(df))\n\u001b[32m--> \u001b[39m\u001b[32m207\u001b[39m model = \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    208\u001b[39m \u001b[38;5;66;03m# example recommend\u001b[39;00m\n\u001b[32m    209\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mExample recommendation for AAPL:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 138\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(df)\u001b[39m\n\u001b[32m    137\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mtrain_model\u001b[39m(df):\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m     X = \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmomentum_1y\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmomentum_3y\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mvol_1y\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mavg_vol_1y\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpe\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpb\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdiv_yield\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmarketcap\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m.fillna(\u001b[32m0\u001b[39m)\n\u001b[32m    139\u001b[39m     y = df[\u001b[33m'\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m    140\u001b[39m     \u001b[38;5;66;03m# time-based split\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/frame.py:4108\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4106\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[32m   4107\u001b[39m         key = \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m4108\u001b[39m     indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolumns\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m]\n\u001b[32m   4110\u001b[39m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[38;5;28mbool\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/indexes/base.py:6200\u001b[39m, in \u001b[36mIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n\u001b[32m   6197\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6198\u001b[39m     keyarr, indexer, new_indexer = \u001b[38;5;28mself\u001b[39m._reindex_non_unique(keyarr)\n\u001b[32m-> \u001b[39m\u001b[32m6200\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6202\u001b[39m keyarr = \u001b[38;5;28mself\u001b[39m.take(indexer)\n\u001b[32m   6203\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[32m   6204\u001b[39m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/indexes/base.py:6249\u001b[39m, in \u001b[36mIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n\u001b[32m   6247\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[32m   6248\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m nmissing == \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[32m-> \u001b[39m\u001b[32m6249\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   6251\u001b[39m     not_found = \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask.nonzero()[\u001b[32m0\u001b[39m]].unique())\n\u001b[32m   6252\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"None of [Index(['momentum_1y', 'momentum_3y', 'vol_1y', 'avg_vol_1y', 'pe', 'pb',\\n       'div_yield', 'marketcap'],\\n      dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "# long_term_recommender.py\n",
    "\"\"\"\n",
    "Simple long-term investment recommender.\n",
    "- Builds training data from historical S&P500 tickers (Wikipedia table).\n",
    "- Fetches price history + some fundamentals via yfinance.\n",
    "- Labels: forward 3-year annualized return > THRESHOLD => good long-term invest.\n",
    "- Trains a RandomForest classifier with time-based split.\n",
    "- Exposes recommend_ticker(ticker) to return probability + recommendation.\n",
    "\"\"\"\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "import joblib\n",
    "import requests\n",
    "\n",
    "# PARAMETERS\n",
    "FORWARD_YEARS = 3\n",
    "RETURN_THRESHOLD_ANNUAL = 0.08  # 8% annualized -> label=1 if forward annualized > 8%\n",
    "MIN_HISTORY_YEARS = 5\n",
    "TRAIN_CUTOFF_YEAR = 2018  # train on data before this year, test on >= this year\n",
    "MODEL_PATH = \"lt_recommender.joblib\"\n",
    "\n",
    "######## utilities ########\n",
    "def get_sp500_tickers():\n",
    "    # pulls the S&P500 table from Wikipedia\n",
    "    url = \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n",
    "    tables = pd.read_html(url)\n",
    "    # first table is the constituents\n",
    "    df = tables[0]\n",
    "    return sorted(df['Symbol'].str.replace('.', '-', regex=False).tolist())\n",
    "\n",
    "def download_price_history(ticker, start, end):\n",
    "    # returns daily price df\n",
    "    return yf.download(ticker, start=start, end=end, progress=False)\n",
    "\n",
    "def get_info(ticker):\n",
    "    t = yf.Ticker(ticker)\n",
    "    return t.info if hasattr(t, \"info\") else {}\n",
    "\n",
    "def compute_features_for_date(ticker, reference_date):\n",
    "    \"\"\"\n",
    "    reference_date: pd.Timestamp or datetime. compute features looking BACK from this date.\n",
    "    \"\"\"\n",
    "    end = reference_date\n",
    "    start = end - pd.DateOffset(years=5)  # 5 years history for features\n",
    "    hist = download_price_history(ticker, start.strftime(\"%Y-%m-%d\"), end.strftime(\"%Y-%m-%d\"))\n",
    "    if hist.empty or len(hist) < 30:\n",
    "        return None\n",
    "    # returns\n",
    "    hist['ret'] = hist['Adj Close'].pct_change()\n",
    "    # feature examples\n",
    "    # 1-year and 3-year momentum using trailing returns (approx using business days)\n",
    "    try:\n",
    "        price_now = hist['Adj Close'].iloc[-1]\n",
    "    except Exception:\n",
    "        return None\n",
    "    # get price 252 trading days (~1 year) ago and 252*3 for ~3 years, fallback to nearest\n",
    "    def trailing_return(days):\n",
    "        if len(hist) <= days: return np.nan\n",
    "        return price_now / hist['Adj Close'].iloc[-(days+1)] - 1\n",
    "    momentum_1y = trailing_return(252)\n",
    "    momentum_3y = trailing_return(252*3)\n",
    "    vol_1y = hist['ret'].std() * np.sqrt(252)\n",
    "    avg_vol_1y = hist['Volume'].tail(252).mean()\n",
    "    info = get_info(ticker)\n",
    "    pe = info.get('trailingPE', np.nan)\n",
    "    pb = info.get('priceToBook', np.nan) if 'priceToBook' in info else info.get('priceToSales', np.nan)\n",
    "    div_yield = info.get('dividendYield', np.nan)\n",
    "    marketcap = info.get('marketCap', np.nan)\n",
    "    # basic features into a vector\n",
    "    features = {\n",
    "        'ticker': ticker,\n",
    "        'date': pd.to_datetime(end),\n",
    "        'momentum_1y': momentum_1y,\n",
    "        'momentum_3y': momentum_3y,\n",
    "        'vol_1y': vol_1y,\n",
    "        'avg_vol_1y': avg_vol_1y,\n",
    "        'pe': pe,\n",
    "        'pb': pb,\n",
    "        'div_yield': div_yield,\n",
    "        'marketcap': marketcap\n",
    "    }\n",
    "    return features\n",
    "\n",
    "def forward_annualized_return(ticker, reference_date, years=FORWARD_YEARS):\n",
    "    start_date = pd.to_datetime(reference_date)\n",
    "    end_date = start_date + pd.DateOffset(years=years)\n",
    "    hist = download_price_history(ticker, start_date.strftime(\"%Y-%m-%d\"), (end_date + pd.DateOffset(days=1)).strftime(\"%Y-%m-%d\"))\n",
    "    if hist.empty or len(hist) < 5:\n",
    "        return np.nan\n",
    "    price_start = hist['Adj Close'].iloc[0]\n",
    "    price_end = hist['Adj Close'].iloc[-1]\n",
    "    total_return = price_end / price_start - 1.0\n",
    "    ann = (1+total_return) ** (1.0/years) - 1.0\n",
    "    return ann\n",
    "\n",
    "######## building dataset ########\n",
    "def build_dataset(sample_tickers=None, start_year=2005, end_year=2019, step_months=12):\n",
    "    \"\"\"\n",
    "    sample_tickers: list of tickers or None -> use S&P500 constituents.\n",
    "    For each ticker and for each reference_date in range(start_year..end_year),\n",
    "    compute features and label (forward 3-year ann return > threshold).\n",
    "    \"\"\"\n",
    "    if sample_tickers is None:\n",
    "        sample_tickers = get_sp500_tickers()\n",
    "    rows = []\n",
    "    for ticker in sample_tickers:\n",
    "        # generate yearly reference dates from start_year to end_year\n",
    "        for year in range(start_year, end_year+1):\n",
    "            ref = pd.Timestamp(year=year, month=1, day=2)  # Jan 2 of each year as anchor\n",
    "            features = compute_features_for_date(ticker, ref)\n",
    "            if features is None:\n",
    "                continue\n",
    "            fwd = forward_annualized_return(ticker, ref, years=FORWARD_YEARS)\n",
    "            if np.isnan(fwd):\n",
    "                continue\n",
    "            label = int(fwd > RETURN_THRESHOLD_ANNUAL)\n",
    "            features['fwd_ann_return'] = fwd\n",
    "            features['label'] = label\n",
    "            rows.append(features)\n",
    "    df = pd.DataFrame(rows)\n",
    "    # drop rows with too many nans\n",
    "    df = df.dropna(thresh=4)\n",
    "    return df\n",
    "\n",
    "######## training ########\n",
    "def train_model(df):\n",
    "    X = df[['momentum_1y','momentum_3y','vol_1y','avg_vol_1y','pe','pb','div_yield','marketcap']].fillna(0)\n",
    "    y = df['label']\n",
    "    # time-based split\n",
    "    train_mask = df['date'].dt.year < TRAIN_CUTOFF_YEAR\n",
    "    X_train, y_train = X[train_mask], y[train_mask]\n",
    "    X_test, y_test = X[~train_mask], y[~train_mask]\n",
    "    pipe = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('clf', RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1))\n",
    "    ])\n",
    "    pipe.fit(X_train, y_train)\n",
    "    preds = pipe.predict(X_test)\n",
    "    probs = pipe.predict_proba(X_test)[:,1]\n",
    "    print(\"TEST METRICS:\")\n",
    "    print(classification_report(y_test, preds))\n",
    "    try:\n",
    "        print(\"ROC AUC:\", roc_auc_score(y_test, probs))\n",
    "    except Exception:\n",
    "        pass\n",
    "    joblib.dump(pipe, MODEL_PATH)\n",
    "    print(\"Saved model to\", MODEL_PATH)\n",
    "    return pipe\n",
    "\n",
    "######## recommend function ########\n",
    "def load_or_train_model(df=None):\n",
    "    try:\n",
    "        model = joblib.load(MODEL_PATH)\n",
    "        print(\"Loaded model from\", MODEL_PATH)\n",
    "        return model\n",
    "    except Exception:\n",
    "        if df is None:\n",
    "            raise RuntimeError(\"No saved model found; pass a dataset to train.\")\n",
    "        return train_model(df)\n",
    "\n",
    "def recommend_ticker(ticker, model=None):\n",
    "    # fetch features for today (or last market day)\n",
    "    today = pd.Timestamp(dt.date.today())\n",
    "    features = compute_features_for_date(ticker, today)\n",
    "    if features is None:\n",
    "        return {\"error\": \"Not enough data for ticker\"}\n",
    "    X = pd.DataFrame([[\n",
    "        features['momentum_1y'],\n",
    "        features['momentum_3y'],\n",
    "        features['vol_1y'],\n",
    "        features['avg_vol_1y'],\n",
    "        features['pe'],\n",
    "        features['pb'],\n",
    "        features['div_yield'],\n",
    "        features['marketcap']\n",
    "    ]], columns=['momentum_1y','momentum_3y','vol_1y','avg_vol_1y','pe','pb','div_yield','marketcap']).fillna(0)\n",
    "    if model is None:\n",
    "        model = joblib.load(MODEL_PATH)\n",
    "    prob = model.predict_proba(X)[0,1]\n",
    "    rec = \"Invest (long-term)\" if prob > 0.6 else (\"Neutral\" if prob > 0.45 else \"Do not invest\")\n",
    "    return {\n",
    "        \"ticker\": ticker,\n",
    "        \"probability_good_long_term\": float(prob),\n",
    "        \"recommendation\": rec,\n",
    "        \"features_snapshot\": features\n",
    "    }\n",
    "\n",
    "######## example main ########\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Building dataset (this may take a while; you can limit tickers)...\")\n",
    "    # Warning: building the dataset for all S&P500 tickers is network heavy.\n",
    "    # For quick testing: pass sample_tickers = ['AAPL','MSFT','AMZN','GOOGL','TSLA']\n",
    "    df = build_dataset(sample_tickers=['AAPL','MSFT','AMZN','GOOGL','TSLA'],\n",
    "                       start_year=2008, end_year=2018)\n",
    "    print(\"Dataset rows:\", len(df))\n",
    "    model = train_model(df)\n",
    "    # example recommend\n",
    "    print(\"Example recommendation for AAPL:\")\n",
    "    print(recommend_ticker(\"AAPL\", model=model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93118b1a-3da1-4ec7-bee8-9e80cdb04625",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
